% =================================================================
% فصل ۱۷: قانون حفاظت از داده‌ها و علم داده مسئولانه (نسخه اصلاح شده)
% =================================================================

\clearpage
\raggedbottom 

% تنظیم شماره‌گذاری فصل روی ۱۷
\setcounter{section}{17}
\setcounter{subsection}{0}
\renewcommand{\thesection}{17}
\renewcommand{\thesubsection}{17.\arabic{subsection}}

% -----------------------------------------------------------------
% عنوان و نویسنده
% -----------------------------------------------------------------
\noindent
\fcolorbox{black}{gray!15}{%
	\begin{minipage}{\dimexpr\linewidth-2\fboxsep-2\fboxrule}
		\vspace{0.5cm}
		\begin{center}
			\textbf{\huge قانون حفاظت از داده‌ها و علم داده مسئولانه}
			\vspace{0.4cm}
			
			\large
			\textit{رافائل گلرت} \\
			\lr{\textit{Raphaël Gellert}}
		\end{center}
		\vspace{0.5cm}
	\end{minipage}
}

\vspace{0.8cm}

% -----------------------------------------------------------------
% فهرست مطالب داخلی
% -----------------------------------------------------------------
\noindent
\textbf{\Large فهرست مطالب}
\vspace{0.3cm}

{ \small
	\noindent \textbf{۱۷.۱} \hspace{0.3cm} \textbf{مقدمه} \par \vspace{0.1cm}
	
	\noindent \textbf{۱۷.۲} \hspace{0.3cm} \textbf{چند کلمه در باب معنای حریم خصوصی و حفاظت از داده‌ها} \par \vspace{0.1cm}
	
	\noindent \textbf{۱۷.۳} \hspace{0.3cm} \textbf{دامنه مادی قانون حفاظت از داده‌ها: تعریف پردازش و داده‌های شخصی} \par 
	\hspace{0.8cm} ۱۷.۳.۱ تعریف پردازش \par
	\hspace{0.8cm} ۱۷.۳.۲ تعریف داده‌های شخصی \par
	\hspace{0.8cm} ۱۷.۳.۳ نتیجه‌گیری: داده‌های شخصی و داده‌های غیرشخصی \par \vspace{0.1cm}
	
	\noindent \textbf{۱۷.۴} \hspace{0.3cm} \textbf{دامنه شخصی حفاظت از داده‌ها: کنترل‌کننده و پردازشگر} \par
	\hspace{0.8cm} ۱۷.۴.۱ سه بازیگر اصلی حفاظت از داده‌ها \par
	\hspace{0.8cm} ۱۷.۴.۲ کنترل‌کنندگان داده \par
	\hspace{0.8cm} ۱۷.۴.۳ پردازشگران داده \par
	\hspace{0.8cm} ۱۷.۴.۴ موقعیت‌های مسئله‌ساز \par \vspace{0.1cm}
	
	\noindent \textbf{۱۷.۵} \hspace{0.3cm} \textbf{ماده ۶ \lr{GDPR}: نیاز به مبنای قانونی برای پردازش} \par
	\hspace{0.8cm} ۱۷.۵.۱ رضایت \par
	\hspace{0.8cm} ۱۷.۵.۲ قرارداد \par
	\hspace{0.8cm} ۱۷.۵.۳ منافع حیاتی موضوع داده \par
	\hspace{0.8cm} ۱۷.۵.۴ انجام وظیفه‌ای در جهت منافع عمومی \par
	\hspace{0.8cm} ۱۷.۵.۵ انطباق با یک تعهد قانونی \par
	\hspace{0.8cm} ۱۷.۵.۶ منافع مشروع کنترل‌کننده داده یا شخص ثالث \par \vspace{0.1cm}
	
	\noindent \textbf{۱۷.۶} \hspace{0.3cm} \textbf{ماده ۵ \lr{GDPR}: اصولی که باید در پردازش داده‌ها اعمال شوند} \par
	\hspace{0.8cm} ۱۷.۶.۱ اصل محدودیت هدف \par
	\hspace{0.8cm} ۱۷.۶.۲ کمینه‌سازی داده‌ها \par
	\hspace{0.8cm} ۱۷.۶.۳ محدودیت ذخیره‌سازی \par
	\hspace{0.8cm} ۱۷.۶.۴ تعهدات اضافی \par \vspace{0.1cm}
	
}

\vspace{0.8cm}

% -----------------------------------------------------------------
% اهداف یادگیری (Learning Objectives)
% -----------------------------------------------------------------
\noindent
\fcolorbox{black}{gray!15}{%
	\begin{minipage}{\dimexpr\linewidth-2\fboxsep-2\fboxrule}
		\vspace{0.3cm}
		\textbf{\large اهداف یادگیری}
		
		\vspace{0.2cm}
		\begin{itemize}
			\setlength\itemsep{0.5em}
			\item[\textbf{--}] درک تفاوت بین حریم خصوصی و حفاظت از داده‌ها
			\item[\textbf{--}] درک چگونگی عملکرد قانون حفاظت از داده‌ها
			\item[\textbf{--}] درک و توانایی تشخیص اینکه آیا یک داده، شخصی محسوب می‌شود یا خیر
			\item[\textbf{--}] درک و توانایی تعیین وظایف بازیگران تحت قانون حفاظت از داده‌ها
			\item[\textbf{--}] درک و توانایی انتخاب مبنای صحیح برای پردازش داده‌های شخصی
			\item[\textbf{--}] درک و توانایی به‌کارگیری صحیح اصولی که بر پردازش داده‌ها اعمال می‌شوند
		\end{itemize}
		\vspace{0.2cm}
	\end{minipage}
}

\vspace{0.8cm} % فاصله قبل از شروع متن اصلی



\subsection{مقدمه}
\label{sec:17-intro}

این فصل مقدمه‌ای بر قانون حفاظت از داده‌ها را برای دانشمندان داده فراهم می‌کند. علم داده بر جمع‌آوری و تحلیل داده‌ها متکی است. حفاظت از داده‌ها مجموعه‌ای از قوانین است که تعیین می‌کند چه نوع عملیاتی روی داده‌ها قابل انجام است و تحت چه شرایطی.

به همین دلیل، برای دانشمندان داده حیاتی است که دانش پایه‌ای از اصول اصلی قانون حفاظت از داده‌ها داشته باشند تا بتوانند علم داده را به شیوه‌ای «از نظر اجتماعی مسئولانه» انجام دهند. این فصل توضیحی کلی از اصول کلیدی را به گونه‌ای ارائه می‌دهد که به شما اجازه می‌دهد هنگام مواجهه با یک کاربرد علم داده، همان‌طور که مثال زیر نشان می‌دهد، از آن‌ها استفاده کنید.

\vspace{0.4cm}

% کادر سوالات کلیدی (مطابق تصویر)
\begin{center}
	\colorbox{gray!15}{%
		\begin{minipage}{0.9\linewidth}
			\vspace{0.2cm}
			\noindent
			$\blacktriangleright$ \textbf{سوالات کلیدی}
			\vspace{0.2cm}
			
			شرکت \lr{X} یک بازار آنلاین است. بنابراین به مقدار مشخصی از اطلاعات مشتری مانند آدرس، نام یا اطلاعات کارت اعتباری نیاز دارد. با این حال، به نظر می‌رسد که شرکت \lr{X} همچنین از این اطلاعات برای ایجاد «پروفایل‌های گرایش سیاسی» \lr{(political affinity profiles)} (یعنی پروفایل‌های مربوط به جهت‌گیری سیاسی مشتریان خود) استفاده می‌کند.
			
			این پروفایل‌ها سپس به احزاب سیاسی فروخته یا اجاره داده می‌شوند تا آن‌ها بتوانند تبلیغات هدفمند ارسال کنند. قوانین حاکم بر این نوع پردازش داده‌ها چیست؟ آیا این کار اصلاً قانونی است؟ $\blacktriangleleft$
			\vspace{0.2cm}
		\end{minipage}
	}
\end{center}

\vspace{0.4cm}

این فصل در چهار گام پیش می‌رود. اول، ملاحظات مقدماتی را در مورد آنچه منظور از قانون حفاظت از داده‌ها (اروپا) است و تفاوت آن با حق حریم خصوصی ارائه می‌دهد. دوم، به دامنه حفاظت از داده‌ها نگاه می‌کند. این شامل هم «دامنه مادی» (داده شخصی چیست) و هم «دامنه شخصی» (بازیگران چه کسانی هستند) می‌شود.

سوم، شرایطی را بررسی می‌کند که تحت آن شروع پردازش داده‌ها امکان‌پذیر است. در نهایت، اصولی را بررسی می‌کند که باید هنگام پردازش واقعی داده‌ها رعایت شوند.





% =================================================================
% متن بخش ۱۷.۲: چند کلمه در باب معنای حریم خصوصی و حفاظت از داده‌ها
% =================================================================

\subsection{چند کلمه در باب معنای حریم خصوصی و حفاظت از داده‌ها}
\label{sec:17-privacy-meaning}

حق حریم خصوصی یکی از حقوق کلیدی دولت‌های دموکراتیک (اروپایی) است. این یک حق پیچیده و چندوجهی است. این حق ابتدا به عنوان حقِ «رها شدن به حال خود» \lr{(right “to be let alone”)} مفهوم‌سازی شد که با مسائل صمیمیت، محرمانگی مکاتبات، حفاظت از محل سکونت و غیره مرتبط بود \lr{(see Gutwirth, 2002)}.

در اروپا، حق حریم خصوصی توسط دو نهاد فراملی محافظت می‌شود: اتحادیه اروپا \lr{(EU)} و شورای اروپا \lr{(CoE)}.\footnote{در حالی که حقوق بنیادین تنها بخش کوچکی از صلاحیت‌های اتحادیه اروپا هستند، شورای اروپا یک سازمان بین‌المللی است که در حفاظت از حقوق بنیادین تخصص دارد. این سازمان در حال حاضر ۴۷ کشور عضو دارد. این شامل تمام کشورهای عضو اتحادیه اروپا می‌شود، اما بسیاری دیگر را نیز در بر می‌گیرد؛ نگاه کنید به: \lr{https://www.coe.int/en/web/about-us/who-we-are}.}

حق حریم خصوصی فراتر رفته و مسائل بسیار بیشتری را پوشش می‌دهد، مانند حقِ انجام انتخاب‌های شخصیِ اساسی مثل نام فرد، گرایش جنسی، جنسیت، سلامت و هویت \lr{(see Gutwirth, 2002)}. به همین دلیل، حق حریم خصوصی در اروپا اکنون با «تعیین سرنوشت» \lr{(self-determination)} و «خودمختاری» \lr{(autonomy)} مرتبط است \lr{(see Gutwirth, 2002)}.

این فصل تنها بر یک جنبه از حق حریم خصوصی تمرکز دارد که گاهی اوقات به عنوان «حریم خصوصی داده» \lr{(data privacy)} نامیده می‌شود \lr{(see, Hoofnagle, Sloot, Zuiderveen Borgesius, 2019, p. 70)}؛ یعنی مسائل حریم خصوصی که هنگام پردازش داده‌های شخصی ما توسط کامپیوترها ایجاد می‌شود. این همان چیزی است که «حفاظت از داده‌ها» درباره آن است.

بنابراین، قانون حفاظت از داده‌ها می‌تواند به عنوان قانون/چارچوب حقوقی درک شود که تعیین می‌کند داده‌های شخصی ما چگونه باید پردازش شوند تا از نقض حق حریم خصوصی ما (و سایر حقوق بنیادین مانند عدم تبعیض) جلوگیری شود.

این فصل بر اتحادیه اروپا تمرکز دارد، زیرا اخیراً قانونی را تصویب کرده است که می‌توان آن را جامع‌ترین قانون حفاظت از داده‌ها نامید و مستقیماً در تمام کشورهای عضو اتحادیه اروپا قابل اجراست: «مقررات عمومی حفاظت از داده‌ها» یا همان \lr{GDPR}. توجه داشته باشید که حفاظت از داده‌ها نیز یک حق بنیادین اتحادیه اروپا است که در ماده ۸ منشور حقوق بنیادین اتحادیه اروپا درج شده است.

در نهایت، باید چند کلمه در مورد ایالات متحده گفته شود. اگرچه سیستم حقوقی ایالات متحده دارای قوانینی است که پردازش داده‌ها را تنظیم می‌کند، اما مفهوم «حفاظت از داده‌ها» را به رسمیت نمی‌شناسد. در آنجا، همه چیز تحت عنوان حریم خصوصی، حریم خصوصی اطلاعات، یا اخیراً حریم خصوصی مصرف‌کننده برچسب‌گذاری می‌شود، حتی اگر در مورد حفاظت از داده‌ها باشد \lr{(see Hoofnagle, Sloot, Zuiderveen Borgesius, 2019, p. 70)}.

مقررات \lr{GDPR} می‌تواند به عنوان یک قانون «جامع» \lr{(omnibus)} تصور شود. این بدان معناست که همه چیز در یک قانون گنجانده شده است که برای همه فعالیت‌ها و همه افراد اعمال می‌شود: نهادهای اداری، کسب‌وکارها، سایر طرف‌های خصوصی و غیره.

در مقابل، قوانین در سیستم ایالات متحده نمی‌توانند به عنوان قانون جامع در نظر گرفته شوند: در سطح فدرال، ایالات متحده قوانین معدودی دارد که فقط بخش‌های خاصی را مورد خطاب قرار می‌دهند، مانند «قانون قابلیت انتقال و پاسخگویی بیمه سلامت» \lr{(HIPAA)} یا «قانون گزارش‌دهی اعتباری منصفانه» \lr{(FCRA)}. فعالیت‌های تجاری عمدتاً توسط «کمیسیون تجارت فدرال» \lr{(FTC)} تنظیم می‌شوند که تنظیم‌کننده (نهاد نظارتی) حفاظت از مصرف‌کننده است. از سال ۱۹۹۵، این کمیسیون صلاحیت خود را برای تنظیم «شیوه‌های ناعادلانه و فریبکارانه» گسترش داده تا مسائل مربوط به پردازش داده‌های شخصی را نیز شامل شود \lr{(see, Gellman, 2019)}.

به‌طور کلی، منصفانه است که بگوییم سطح حفاظت در ایالات متحده بسیار پایین‌تر از اتحادیه اروپا است. فراتر از پیچیدگی و ناهماهنگی‌های چارچوب قانونی و فقدان یک نهاد نظارتی واقعی حفاظت از داده‌ها، حفاظت واقعی بسیار کمتر است. برخی از عناصر مهم عبارتند از تعریف محدودِ داده‌های شخصی (در مقایسه با تعریف اروپایی که در این فصل به طور گسترده بحث می‌شود) و سیستمی که عمدتاً بر اساس رضایت است (به‌اصطلاح «اطلاع‌رسانی و رضایت» \lr{notice and consent})، که در عمل حفاظت کمتری ارائه می‌دهد، به ویژه در مقایسه با چارچوب اروپایی \lr{(see, Gellman, 2019)}.

با این حال، تغییر در راه است: برای مثال، کالیفرنیا «قانون حریم خصوصی مصرف‌کننده کالیفرنیا» \lr{(CCPA)} را در سال ۲۰۱۸ تصویب کرده است که از \lr{GDPR} الهام گرفته است (اما فقط محدود به کالیفرنیا است). در سطح فدرال، «قانون حفاظت و امنیت داده‌های مصرف‌کننده ۲۰۲۰» \lr{(CDPSA)} در مارس ۲۰۲۰ مطرح شده است.

این فصل چهار جنبه زیر از \lr{GDPR} را در نظر می‌گیرد. اول، دامنه آن را، هم شخصی و هم مادی، بررسی خواهد کرد. یعنی قانون حفاظت از داده‌ها چه زمانی اعمال می‌شود و برای چه کسانی اعمال می‌شود؟ سپس به برخی از مهم‌ترین مقررات ماهوی نگاه خواهد کرد، یعنی اصول اصلی که در مواد ۵ و ۶ \lr{GDPR} درج شده‌اند. این‌ها تعیین می‌کنند که تحت چه شرایطی شروع پردازش داده‌های شخصی امکان‌پذیر است و چه اصولی باید هنگام انجام چنین پردازشی رعایت شوند.
% متن بخش ۱۷.۲ اینجا قرار می‌گیرد

% =================================================================
% متن بخش ۱۷.۳: دامنه مادی (با شماره‌گذاری اتوماتیک تا سطح ۴)
% =================================================================

% فعال‌سازی شماره‌گذاری تا سطح ۴ (برای نمایش ۱۷.۳.۲.۱)
\setcounter{secnumdepth}{4}
\renewcommand{\theparagraph}{\thesubsubsection.\arabic{paragraph}}

\subsection{دامنه مادی قانون حفاظت از داده‌ها: تعریف پردازش و داده‌های شخصی}
\label{sec:17-3-material-scope}

دامنه مادی را می‌توان ارجاع به «چه چیز» \lr{(what)} دانست: قانون حفاظت از داده‌ها بر چه چیزی اعمال می‌شود؟ پاسخ، پردازشِ (بخش ۱۷.۳.۱) داده‌های شخصی (بخش ۱۷.۳.۲) است.

\subsubsection{تعریف پردازش}
\label{sec:17-3-1-processing}

قانون حفاظت از داده‌ها بر «پردازش داده‌های شخصی که تماماً یا بخشی از آن به صورت خودکار انجام می‌شود» طبق ماده ۲(۱) مقررات \lr{GDPR} اعمال می‌شود. ابزارهای خودکار شامل کامپیوترها و هر نوع دستگاه دیجیتال است.

پردازش به نوبه خود به معنای «هرگونه عملیات یا مجموعه‌ای از عملیات است که بر روی داده‌های شخصی انجام می‌شود» (ماده ۴(۲)، \lr{GDPR}). این بدان معناست که چرخه عمر یک عملیات پردازش از لحظه جمع‌آوری داده‌ها آغاز می‌شود و زمانی پایان می‌یابد که داده‌ها نابود یا ناشناس‌سازی شوند (نگاه کنید به بخش ۱۷.۴.۲). در فاصله بین این دو لحظه (و شامل آن‌ها)، هر عملیاتی که روی داده‌های شخصیِ مورد نظر انجام شود، یک «پردازش» تلقی خواهد شد.

\subsubsection{تعریف داده‌های شخصی}
\label{sec:17-3-2-personal-data}

داده‌های شخصی در ماده ۴(۱) مقررات \lr{GDPR} به عنوان «هرگونه اطلاعات مربوط به یک شخص حقیقی شناسایی‌شده یا قابل شناسایی (موضوع داده یا \lr{Data Subject})» تعریف شده است. به زبان ساده‌تر، داده‌های شخصی، داده‌هایِ موضوعِ داده هستند که در حال پردازش می‌باشند (یعنی داده‌های شما).

همان‌طور که مشاهده می‌شود، این تعریف شامل چهار عنصر کلیدی است که در زیر به اختصار بررسی می‌شوند.

% سطح ۴: ۱۷.۳.۲.۱
\paragraph{«هرگونه اطلاعات»}
\label{sec:17-3-2-1-any-info}
\mbox{}\\
کاملاً روشن نیست چرا \lr{GDPR} در نظر می‌گیرد که داده شخصی، «اطلاعات» است (به جای داده). برای ساده‌سازی، هر دو اصطلاح در این فصل به عنوان مترادف در نظر گرفته می‌شوند.
طبق نظر «کارگروه حفاظت از داده ماده ۲۹» \lr{(Art. 29 WP)}، آنچه تحت عنوان اطلاعات در \lr{GDPR} واجد شرایط است، بسیار گسترده می‌باشد. مهم نیست که اطلاعات خصوصی باشد یا عمومی، درست باشد یا غلط، و ذهنی باشد یا عینی. علاوه بر این، تا زمانی که برای پردازش توسط ابزارهای خودکار مناسب باشد، هر فرمتی قابل قبول است (مثلاً بایت‌های دیجیتال، صوتی، ویدئویی، نقاشی).

% سطح ۴: ۱۷.۳.۲.۲
\paragraph{«مربوط به»}
\label{sec:17-3-2-2-relating-to}
\mbox{}\\
اینکه داده‌ها به موضوع داده «مربوط» باشند، به سادگی به این معناست که این داده‌ها باید «درباره» موضوع داده باشند. این می‌تواند به روش‌های مختلفی باشد. ساده‌ترین راه زمانی است که «محتوای» داده‌ها (به وضوح) به این موضوع داده مربوط باشد؛ برای مثال، زمانی که داده‌ها حاوی نام، آدرس و شماره تأمین اجتماعی یک شخص باشد.

با این حال، داده‌های شخصی همچنین می‌توانند به روش‌های پیچیده‌تری که فراتر از محتوای دقیق داده‌هاست، به موضوعات داده مربوط شوند. این حالت در دو وضعیت رخ می‌دهد: زمانی که داده‌ها از نظر «هدف» \lr{(purpose)} یا از نظر «نتیجه» \lr{(result)} مرتبط باشند.
داده‌ها زمانی از نظر **هدف** مرتبط هستند که با هدفِ ارزیابی، رفتار به شیوه‌ای خاص، یا تأثیرگذاری بر موضوع داده پردازش شوند.
در نهایت، داده‌ها می‌توانند از نظر **نتیجه** (یا تأثیر) به موضوع داده مربوط شوند، زمانی که داده‌ها به شیوه‌ای پردازش می‌شوند که در پایان راه، تأثیری بر موضوع داده داشته باشند.

% سطح ۴: ۱۷.۳.۲.۳
\paragraph{«شناسایی‌شده یا قابل شناسایی»}
\label{sec:17-3-2-3-identifiable}
\mbox{}\\
داده‌ها نه تنها باید به موضوع داده «مربوط» باشند، بلکه موضوع داده نیز باید «شناسایی‌شده» یا «قابل شناسایی» باشد.
مقررات \lr{GDPR} بین موضوعات داده‌ای که «شناسایی‌شده» هستند و آن‌هایی که «قابل شناسایی» هستند تمایز قائل می‌شود.

موضوع داده زمانی **شناسایی‌شده** است که کنترل‌کننده/پردازشگر داده از قبل در مجموعه داده‌های خود اطلاعاتی دارد که موضوع داده را شناسایی می‌کند (یعنی او را متمایز می‌کند). این می‌تواند نام یا شناسه (منحصر به فرد) دیگری مانند شماره تلفن همراه یا کد ملی باشد.

موضوع داده زمانی **قابل شناسایی** است که کنترل‌کننده اطلاعات مستقیمی ندارد، اما با این وجود قادر به شناسایی موضوع داده است (مثلاً با ترکیب داده‌ها). \lr{GDPR} استدلال می‌کند که شناسایی موضوع داده می‌تواند توسط کسانی که داده‌ها را پردازش می‌کنند یا هر شخص ثالث دیگری انجام شود.

معیار تعیین اینکه آیا یک موضوع داده قابل شناسایی است یا خیر، استفاده از تمام ابزارهایی است که «احتمالاً به‌طور معقول برای شناسایی استفاده می‌شوند». می‌توان بین ابزارهای «فنی» (افزودن اطلاعات به داده‌ها) و ابزارهای «سازمانی» (زمینه و انگیزه کنترل‌کننده) تمایز قائل شد.

% سطح ۴: ۱۷.۳.۲.۴
\paragraph{«شخص حقیقی (موضوع داده)»}
\label{sec:17-3-2-4-natural-person}
\mbox{}\\
شخص در عبارت «داده‌های شخصی»، یا شخصی که داده‌ها به او مربوط می‌شود، به عنوان «موضوع داده» شناخته می‌شود که باید یک «شخص حقیقی» باشد (ماده ۴(۱)، \lr{GDPR}). در اصل، این به معنای دو چیز است. اول، شخص باید زنده باشد. دوم، شخص نمی‌تواند یک «شخص حقوقی» باشد.

\subsubsection{نتیجه‌گیری: داده‌های شخصی و داده‌های غیرشخصی}
\label{sec:17-3-3-conclusion}

به عنوان راهی برای نتیجه‌گیری این مرور کلی بر مفهوم داده‌های شخصی، می‌توان موارد زیر را گفت. این یک مفهوم بسیار گسترده است که اکثر انواع اطلاعات را در بر می‌گیرد. همچنین مفهومی «وابسته به زمینه» است.

در این رابطه، آزمون شناسایی نشان می‌دهد که داده شخصی همچنین «احتمالی» \lr{(probabilistic)} است. با این حال، آستانه بسیار پایین است، که به این معنی است که در عمل، بسیار دشوار است که یک قطعه داده شخصی نباشد. اما زمانی که چنین باشد (شخصی نباشد)، چنین داده‌های غیرشخصی به عنوان «داده‌های ناشناس» \lr{(anonymous data)} نامیده می‌شوند و از دسترس قانون حفاظت از داده‌ها خارج هستند.

% =================================================================
% متن بخش ۱۷.۴: دامنه شخصی حفاظت از داده‌ها (ترجمه کامل و دقیق)
% =================================================================

% فعال‌سازی شماره‌گذاری تا سطح ۴ (برای نمایش صحیح ۱۷.۴.۴.۱)
\setcounter{secnumdepth}{4}
\renewcommand{\theparagraph}{\thesubsubsection.\arabic{paragraph}}

\subsection{دامنه شخصی حفاظت از داده‌ها: کنترل‌کننده و پردازشگر}
\label{sec:17-4-personal-scope}

\subsubsection{سه بازیگر اصلی حفاظت از داده‌ها}
\label{sec:17-4-1-three-actors}

در اصل، می‌توان استدلال کرد که سه بازیگر کلیدی در قانون حفاظت از داده‌ها وجود دارند:

\begin{itemize}
	\item \textbf{موضوع داده \lr{(The data subject)}} یک شخص حقیقی شناسایی‌شده یا قابل شناسایی است که داده‌های شخصی او در حال پردازش است.
	
	\item \textbf{کنترل‌کنندگان داده \lr{(Data controllers)}} (اشخاص حقیقی یا حقوقی) بازیگران اصلی و صاحبان وظیفه هستند. آن‌ها مسئول و پاسخگو برای انطباق با قانون حفاظت از داده‌ها می‌باشند.
	
	\item \textbf{پردازشگران داده \lr{(Data processors)}} اشخاص حقیقی یا حقوقی مجزایی هستند که داده‌های شخصی را «به نمایندگی از» کنترل‌کننده پردازش می‌کنند. اگرچه مسئولیت آن‌ها در قبال کنترل‌کننده داده است، اما \lr{GDPR} اکنون به مقامات نظارتی اداری اجازه می‌دهد تا مستقیماً آن‌ها را جریمه کنند و تحت شرایط خاصی، آن‌ها نیز می‌توانند در برابر موضوعات داده پاسخگو باشند \lr{(see Rodway \& Carey, 2018, p. 178)}.
\end{itemize}

\subsubsection{کنترل‌کنندگان داده}
\label{sec:17-4-2-controllers}

مقررات \lr{GDPR} یک کنترل‌کننده (داده) را به این صورت تعریف می‌کند: «شخص حقیقی یا حقوقی (...) که به تنهایی یا مشترکاً با دیگران، اهداف و ابزارهای پردازش داده‌های شخصی را تعیین می‌کند» (طبق ماده ۴(۷)، \lr{GDPR}).

یک شخص حقیقی یا حقوقی می‌تواند به یک فرد تنها، یک فرد خوداشتغال، یا شرکت‌هایی مانند بانک‌ها، شرکت‌های بیمه، شرکت‌های حقوقی، سوپرمارکت‌ها، مطب‌های پزشکی و موتورهای جستجوی اینترنتی اشاره داشته باشد \lr{(see Welfare \& Carey, 2018, p. 18)}. این بدان معناست که یک بازیگر اگر «هدف» یا «ابزار»، یا هر دو را تعیین کند، به عنوان کنترل‌کننده داده واجد شرایط خواهد بود.

هدف پردازش، دلیل یا هدف کلی است که چرا داده‌ها در وهله اول پردازش می‌شوند: این موضوع در ادامه این بخش با جزئیات بیشتر بررسی خواهد شد. مقررات \lr{GDPR} در مورد اینکه «ابزار» پردازش دقیقاً به چه معناست، ساکت است. طبق نظر «کارگروه حفاظت از داده ماده ۲۹» \lr{(Art. 29 WP)}، این ابزارها باید به عنوان «ابزارهای ضروری/اساسی» \lr{(essential means)} درک شوند \lr{(Art. 29 WP, 2010, p. 14)}.

این ابزارهای ضروری به حیاتی‌ترین و اساسی‌ترین انتخاب‌هایی اشاره دارند که باید انجام شوند. بنابراین شامل انتخاب‌های زیر می‌شوند: چه داده‌هایی و چه مقدار داده پردازش خواهد شد، برای چه مدت، چه کسی می‌تواند به داده‌ها دسترسی داشته باشد، چه نوع عملیات پردازشی انجام خواهد شد، چه تعداد موضوع داده تحت تأثیر قرار می‌گیرند و غیره \lr{(Art. 29 WP, 2010, p. 14)}.

ابزارهای غیرضروری به عنوان «ابزارهای سازمانی» \lr{(organisational means)} نامیده می‌شوند \lr{(Art. 29 WP, 2010, p. 14)}. آن‌ها شامل مواردی مانند انتخاب سخت‌افزار و نرم‌افزار و اینکه کدام کارمند شرکت با کامپیوترها کار خواهد کرد، می‌شوند \lr{(Art. 29 WP, 2010, p. 14)}. این ابزارها می‌توانند توسط کنترل‌کننده داده یا توسط پردازشگر داده تعیین شوند و تأثیری در تعیین نقش‌ها ندارند.

\subsubsection{پردازشگران داده}
\label{sec:17-4-3-processors}

یک پردازشگر داده «یک شخص حقیقی یا حقوقی (...) است که داده‌های شخصی را به نمایندگی از کنترل‌کننده پردازش می‌کند» (طبق ماده ۴(۸)، \lr{GDPR}). به عبارت دیگر، پردازشگر پردازش داده‌های شخصی را به حساب کنترل‌کننده انجام می‌دهد.

ایده در اینجا یکی از «تفویض اختیار» \lr{(delegation)} است: پردازشگر دستورالعمل‌های کنترل‌کننده را اجرا خواهد کرد \lr{(Art. 29 WP, 2010, p. 25)}. باید در نظر داشت که پردازشگر یک شخص «جداگانه» است. از نظر تئوری، این بدان معناست که تفویض پردازش به کارمند دیگری در همان شرکت، به عنوان پردازشگر داده واجد شرایط نیست \lr{(Art. 29 WP, 2010, p. 25)}.

این می‌تواند شامل یک پیمانکار فرعی برای مدیریت حقوق و دستمزد، ذخیره‌سازی داده‌ها، مدیریت \lr{IT}، میزبانی وب‌سایت، یک تأمین‌کننده رایانش ابری، یا یک مرکز محاسباتی باشد \lr{(Rodway \& Carey, 2018, p. 175; Voigt \& von dem Busche, 2017, p. 20)}.

باید توجه داشت که \lr{GDPR} ملزم می‌کند که تنها پردازشگرانی که «تضامین کافی» برای انطباق با \lr{GDPR} ارائه می‌دهند، می‌توانند به عنوان پردازشگر انتخاب شوند (ماده ۲۸(۱) \lr{GDPR}). علاوه بر این، رابطه بین یک کنترل‌کننده و یک پردازشگر باید توسط یک قرارداد اداره شود (ماده ۲۸(۳) \lr{GDPR}).

مورد اخیر (قرارداد) باید برخی از عناصر کلیدی پردازش را ذکر کند: ماهیت و هدف پردازش، نوع داده‌ها، دسته‌های موضوعات داده و غیره. علاوه بر این، باید شامل تعدادی از تعهدات برای پردازشگر باشد، مانند اتخاذ تدابیر امنیتی مناسب و شفاف بودن با کنترل‌کننده (ماده ۲۸(۳)، \lr{GDPR}).

\subsubsection{موقعیت‌های مسئله‌ساز}
\label{sec:17-4-4-problematic}

تعاریف مربوط به کنترل‌کننده و پردازشگر ممکن است سرراست به نظر برسند، اما کاربرد آن‌ها همیشه آسان نیست. می‌توان دو مسئله را برجسته کرد: منطقه خاکستری بین یک کنترل‌کننده و یک پردازشگر، و چگونگی برخورد با تعدد کنترل‌کنندگان.

\paragraph{کنترل‌کننده یا پردازشگر؟}
\label{sec:17-4-4-1-controller-processor}
\mbox{}\\
اگرچه پردازشگر تنها به نمایندگی از کنترل‌کننده داده پردازش می‌کند، اما ممکن است برخی مناطق خاکستری وجود داشته باشد. از آنجا که پردازشگر داده‌ها را پردازش می‌کند، ممکن است مجبور شود تعدادی انتخاب در مورد چگونگی انجام پردازش انجام دهد. این می‌تواند زمانی باشد که پردازشگر منابع بسیار بیشتری نسبت به کنترل‌کننده دارد، اما نه فقط در این مورد.

آیا این انتخاب‌ها صرفاً اجرای دستورالعمل‌های کنترل‌کننده هستند، یا این‌ها انتخاب‌های واقعی در مورد ابزارهای ضروری پردازش (که حق انحصاری کنترل‌کننده است) می‌باشند؟ سوال کلیدی در اینجا درجه «استقلال» \lr{(autonomy)} است: آیا پردازشگر همچنان به نمایندگی از کنترل‌کننده عمل می‌کرد، یا نفوذ خود را بر پردازش اعمال می‌کرد \lr{(Rodway \& Carey, 2018, p. 182; Voigt \& von dem Busche, 2017, p. 19)}؟

آیا اگر پردازشگر در غیاب دستورالعمل‌های کنترل‌کننده عمل می‌کرد، پردازش داده‌ها همچنان انجام می‌شد (یعنی آیا فضایی برای این نوع تصمیم‌گیری صلاحدیدی وجود دارد) \lr{(Voigt \& von dem Busche, 2017, p. 19)}؟ به عبارت دیگر، چه کسی قدرت تصمیم‌گیری را دارد؟ اگر پاسخ به این سوال مثبت است، پس پردازشگر باید به عنوان یک کنترل‌کننده نیز در نظر گرفته شود و ما با وضعیت «کنترل‌کنندگی مشترک» مواجه هستیم.

\paragraph{کنترل‌کنندگان متعدد}
\label{sec:17-4-4-2-multiple-controllers}
\mbox{}\\
کنترل‌کنندگان داده ابزار و هدف پردازش را «به تنهایی یا مشترکاً با دیگران» تعریف می‌کنند (طبق ماده ۴(۷)، \lr{GDPR}). مقررات \lr{GDPR} مفهوم «کنترل‌کنندگی مشترک» \lr{(joint controllership)} را برای اشاره به موقعیت‌هایی با چندین کنترل‌کننده معرفی کرد (ماده ۲۶ \lr{GDPR}).

با توجه به اینکه فرد با تعریفِ هدف یا ابزار پردازش کنترل‌کننده می‌شود، گونه‌شناسی گسترده‌ای از کنترل‌کنندگی مشترک وجود دارد. کنترل‌کنندگان مشترک می‌توانند رابطه نزدیکی داشته باشند و به همان هدف (و ابزارهای ضروری) پایبند باشند، هدف مشترکی نداشته باشند اما مشترکاً ابزارها را تعیین کنند، یا رابطه آزادتری با اشتراک‌گذاری تنها بخش‌هایی از هدف و/یا ابزارها داشته باشند \lr{(Art. 29 WP, 2010, pp. 17–23)}.

به عنوان کنترل‌کنندگان مشترک، همه بازیگران مسئول انطباق با \lr{GDPR} هستند (نگاه کنید به ماده ۲۶(۳)، \lr{GDPR}). با این حال، مورد اخیر ملزم می‌کند که آن‌ها مسئولیت‌های خود را تخصیص دهند (یعنی «چه کسی چه کاری انجام می‌دهد؟») (ماده ۲۶(۱)، \lr{GDPR}). مقررات \lr{GDPR} در مورد اینکه در عمل چنین مسئولیتی چگونه باید به اشتراک گذاشته شود، اختیار می‌دهد. تنها ملزم می‌کند که کنترل‌کنندگان توافق‌نامه‌ای در این مورد منعقد کنند و آن را شفاف سازند، به ویژه برای موضوعات داده (ماده ۲۶(۱)(۲)، \lr{GDPR}).

% =================================================================
% بخش ۱۷.۵: ماده ۶ GDPR
% =================================================================

\subsection{ماده ۶ \lr{GDPR}: نیاز به مبنای قانونی برای پردازش}
\label{sec:17-5-gdpr-art6}

اگر یک کنترل‌کننده داده بخواهد پردازش داده‌های شخصی را آغاز کند، باید به ماده ۶ مقررات \lr{GDPR} مراجعه کند. این ماده حاوی شش مبنای جایگزین است که پردازش داده‌ها می‌تواند بر اساس آن‌ها انجام شود. به عبارت دیگر، شروع پردازش داده‌های شخصی امکان‌پذیر نیست مگر اینکه یک مبنا برای پردازش انتخاب شده باشد. می‌توان یکی از مبانی زیر را انتخاب کرد:

\begin{enumerate}
	\setlength\itemsep{0.5em}
	\item[(الف)] موضوع داده به پردازش داده‌های شخصی خود «رضایت» داده است (نگاه کنید به بخش ۱۷.۵.۱ این فصل).
	\item[(ب)] پردازش برای «اجرای قراردادی» که موضوع داده طرف آن است، ضروری است (نگاه کنید به بخش ۱۷.۵.۲).
	\item[(ج)] پردازش برای انطباق با یک «تعهد قانونی» ضروری است (نگاه کنید به بخش ۱۷.۵.۵).
	\item[(د)] پردازش به منظور محافظت از «منافع حیاتی» موضوع داده ضروری است (نگاه کنید به بخش ۱۷.۵.۳).
	\item[(هـ)] پردازش برای انجام وظیفه‌ای که در جهت «منافع عمومی» انجام می‌شود، ضروری است (نگاه کنید به بخش ۱۷.۵.۴).
	\item[(و)] پردازش برای مقاصد «منافع مشروع» دنبال شده توسط کنترل‌کننده یا شخص ثالث ضروری است، مگر در مواردی که چنین منافعی توسط منافع یا حقوق و آزادی‌های بنیادین موضوع داده مغلوب شوند (نگاه کنید به بخش ۱۷.۵.۶).
\end{enumerate}

همان‌طور که مشاهده می‌شود، همه مبانی به جز «رضایت» نیاز دارند که پردازش برای مبنای مورد استناد «ضروری» \lr{(necessary)} باشد. الزام ضرورت دلالت بر این دارد که آن مبنا نمی‌تواند با ابزارهای دیگری که برای حقوق بنیادین موضوعات داده محدودیت کمتری دارند، محقق شود \lr{(see Art. 29 WP, 2014, p. 13)}.

\subsubsection{رضایت \lr{(Consent)}}
\label{sec:17-5-1-consent}

رضایت به نشانگرِ آزادانه، مشخص، آگاهانه و بدون ابهامِ خواسته موضوع داده اشاره دارد که توسط آن، او (حداکثر در زمان شروع پردازش) موافقت خود را با پردازش داده‌های شخصی‌اش اعلام می‌کند (طبق ماده ۴(۱۱)، \lr{GDPR}).

% جدول ۱۷.۱
\begin{table}[h!]
	\centering
	\caption{هدف نامشخص و مشخص \lr{(Source: Art. 29 WP, 2018b, p. 9)}}
	\vspace{0.2cm}
	\begin{tabular}{|p{0.45\linewidth}|p{0.45\linewidth}|}
		\hline
		\textbf{مثالی از یک هدف نامشخص} & \textbf{مثالی از یک هدف مشخص} \\
		\hline
		«بهبود تجربه کاربران» & «ما تاریخچه خرید شما را با اشخاص ثالث به اشتراک می‌گذاریم تا محتوای متناسب برای خریدهای آینده را به شما ارائه دهیم» \\
		\hline
	\end{tabular}
	\label{tab:17-1-unspecific-specific}
\end{table}

\paragraph{۱۷.۵.۱.۱ رضایت باید در رابطه با یک هدف مشخص داده شود}
یک هدف زمانی به اندازه کافی مشخص است که به حد کافی دقیق باشد تا موضوع داده بتواند تعیین کند چه نوع پردازشی شامل آن می‌شود و چه نوعی نمی‌شود. به عبارت دیگر، یک پردازش تنها در صورتی تحت پوشش رضایت قرار می‌گیرد که در آن هدف گنجانده شده باشد.
ایده این است که از به‌اصطلاح «رضایت سفید» \lr{(blank consent)} جلوگیری شود (یعنی مانند یک چک سفید امضا، ما رضایت داده‌ایم اما نمی‌دانیم دقیقاً به چه چیزی) \lr{(Art. 29 WP, 2018a, pp. 11–12)}. مثالی از هر دو هدف نامشخص و مشخص را می‌توان در جدول ۱۷.۱ یافت.

\paragraph{۱۷.۵.۱.۲ رضایت باید آگاهانه باشد}
کنترل‌کنندگان داده باید شفاف باشند تا موضوعات داده بتوانند درک کنند که به چه چیزی رضایت می‌دهند \lr{(Art. 29 WP, 2018a, p. 13)}. اصلِ رضایت آگاهانه دو جنبه دارد.
از یک سو، کنترل‌کننده داده را ملزم می‌کند که اطلاعات اضافی را در اختیار موضوع داده قرار دهد. نمونه‌هایی از اطلاعاتی که باید ارائه شوند شامل نام کنترل‌کننده داده، هدف پردازش، انواع داده‌ها و انواع پردازش است \lr{(Art. 29 WP, 2018a, p. 13)}.
از سوی دیگر، این اصل به «کیفیت» اطلاعات ارائه شده مربوط می‌شود. موضوع داده باید بتواند به راحتی آنچه را که کنترل‌کننده می‌گوید درک کند \lr{(Art. 29 WP, 2018a, pp. 13–14)}. این امر استفاده از «اصطلاحات تخصصی حقوقی» \lr{(legal jargon)} را که هنوز هم اغلب در شرایط و ضوابط یافت می‌شود، رد می‌کند. به همین ترتیب، اطلاعات باید «به راحتی قابل دسترسی» باشند (مثلاً آن را با فونت‌های بسیار ریز در انتهای شرایط و ضوابط ننویسید).

\paragraph{۱۷.۵.۱.۳ رضایت باید بدون ابهام باشد}
هدف این است که نباید هیچ شکی در مورد قصد موضوع داده برای رضایت دادن وجود داشته باشد \lr{(Art. 29 WP, 2018a, pp. 15–16)}. خودِ رضایت می‌تواند به هر شکلی داده شود، تا زمانی که موضوع داده فعالانه موافقت خود را اعلام کند. روش‌های مختلفی برای ارائه رضایت وجود دارد، از جمله کتبی، بیانیه شفاهی ضبط شده، تیک زدن جعبه، پارامترهای مرورگر و غیره.

\vspace{0.4cm}
% کادر مثال جعبه‌های از پیش تیک‌خورده
\begin{center}
	\colorbox{gray!15}{%
		\begin{minipage}{0.9\linewidth}
			\vspace{0.2cm}
			\noindent
			$\blacktriangleright$ \textbf{جعبه‌های از پیش تیک‌خورده \lr{(Pre-ticked Boxes)}}
			\vspace{0.2cm}
			
			جعبه‌های از پیش تیک‌خورده (که به عنوان \lr{opt-out} شناخته می‌شوند) روش معتبری برای ابراز رضایت نیستند، زیرا هیچ رضایت فعالی از طرف موضوع داده وجود ندارد. تنها جعبه‌های معتبر، \lr{opt-in} هستند.
			
			\textbf{مثال رضایت نامعتبر برای کوکی‌ها:} جعبه‌های «ترجیحات» و «آمار» از پیش تیک‌خورده هستند، مانند شکل ۱۷.۱. $\blacktriangleleft$
			\vspace{0.2cm}
		\end{minipage}
	}
\end{center}

% شکل ۱۷.۱ (جایگزین عکس با کادر لاتک)
\begin{figure}[h!]
	\centering
	\setlength{\fboxsep}{10pt}
	\fbox{
		\begin{minipage}{0.6\linewidth}
			\begin{latin}
				\textbf{This website uses cookies} \\[0.3cm]
				\small
				\textbf{[x] Preferences} \quad \textbf{[x] Statistics} \quad [ ] Marketing
			\end{latin}
		\end{minipage}
	}
	\caption{رضایت نامعتبر برای کوکی‌ها. منبع: شکل متعلق به نویسنده.}
	\label{fig:17-1-invalid-consent}
\end{figure}

\paragraph{۱۷.۵.۱.۴ رضایت باید آزادانه باشد}
برای اینکه رضایت آزادانه باشد، موضوع داده باید هنگام رضایت دادن یک انتخاب واقعی داشته باشد \lr{(see Art. 29 WP, 2018a, pp. 5–11)}. این در مواردی که موضوع داده مجبور به رضایت دادن است، در معرض ضرر و زیان است، یا هیچ گزینه واقعی ندارد، صدق نمی‌کند.
رضایت در مواردی که با «نابرابری‌های قدرت» مشخص می‌شوند (مانند اشتغال یا مقامات دولتی) اجباری تلقی خواهد شد.
رضایت زمانی در معرض «ضرر و زیان» است که امتناع از رضایت منجر به پیامدهای منفی مانند هزینه‌ها یا از دست دادن خدمات شود.
فقدان انتخاب واقعی به مسائل «شرطی بودن» یا «بسته‌بندی» \lr{(bundling)} اشاره دارد. این به موقعیت‌هایی اشاره دارد که رضایت برای عملیات پردازش با یک قرارداد برای انجام خدمات بسته‌بندی شده است، حتی اگر رضایت به خودی خود برای انجام خدمات ضروری نباشد.

\vspace{0.4cm}
% کادر مثال بسته‌بندی رضایت
\begin{center}
	\colorbox{gray!15}{%
		\begin{minipage}{0.9\linewidth}
			\vspace{0.2cm}
			\noindent
			$\blacktriangleright$ \textbf{بسته‌بندی رضایت \lr{(Bundling of Consent)}}
			\vspace{0.2cm}
			
			یک برنامه موبایل برای ویرایش عکس از کاربرانش می‌خواهد که موقعیت مکانی \lr{GPS} خود را برای استفاده از خدماتش فعال کنند. این برنامه همچنین می‌گوید که از داده‌های جمع‌آوری شده برای اهداف تبلیغات رفتاری استفاده خواهد کرد.
			
			نه موقعیت مکانی و نه تبلیغات رفتاری آنلاین برای ارائه خدمات ویرایش عکس ضروری نیستند. بنابراین، این نوع رضایت معتبر نیست.
			\vspace{0.1cm}
			\footnotesize{نکته: مثال بر اساس \lr{Art. 29 WP (2018a, p. 6)}.} $\blacktriangleleft$
			\vspace{0.2cm}
		\end{minipage}
	}
\end{center}

\paragraph{۱۷.۵.۱.۵ دسته‌های خاص داده‌ها: رضایت صریح}
برای دسته‌های خاصی از داده‌های حساس (مانند نژاد، عقاید سیاسی، داده‌های ژنتیکی)، یک رضایت معمولی کافی نیست و یک «رضایت صریح» مورد نیاز است (ماده ۹، \lr{GDPR}). رضایت باید به‌طور صریح در یک بیانیه کتبی تأیید شود (مثلاً: «من به پردازش داده‌ها برای هدف [x] رضایت می‌دهم»).

\subsubsection{قرارداد}
\label{sec:17-5-2-contract}

یک قرارداد بین یک موضوع داده و یک کنترل‌کننده داده می‌تواند در دو مورد به عنوان مبنایی برای پردازش داده‌های شخصی عمل کند.
اول، پردازش داده‌ها برای «اجرای قرارداد» ضروری است (جدول ۱۷.۲).
دوم، موردی است که پردازش در «مرحله پیش‌قراردادی» ضروری است (یعنی تا قرارداد بتواند ایجاد شود). این تنها در صورتی معتبر است که به درخواست موضوع داده باشد (جدول ۱۷.۳).

% جدول ۱۷.۲
\begin{table}[h!]
	\centering
	\caption{پردازش داده‌ها برای اجرای قرارداد ضروری است \lr{(Source: Voigt \& Von dem Busche, 2017, p. 102)}}
	\vspace{0.2cm}
	\small
	\begin{tabular}{|p{0.15\linewidth}|p{0.38\linewidth}|p{0.38\linewidth}|}
		\hline
		& \textbf{معتبر (Valid)} & \textbf{نامعتبر (Invalid)} \\
		\hline
		پردازش ضروری & نام و آدرس مشتری، نوع و تعداد کالا، روش پرداخت & نام والدین، سن همسر، سایر عادات خرید \\
		\hline
		اجرای قرارداد & تحویل محصولات به مشتری & وصول بدهی، مراجعه به دادگاه در صورت اختلاف \\
		\hline
	\end{tabular}
	\label{tab:17-2-contract-execution}
\end{table}

% جدول ۱۷.۳
\begin{table}[h!]
	\centering
	\caption{پردازش داده‌ها در مرحله پیش‌قراردادی ضروری است \lr{(Source: Voigt \& Von dem Busche, 2017, p. 102)}}
	\vspace{0.2cm}
	\small
	\begin{tabular}{|p{0.2\linewidth}|p{0.35\linewidth}|p{0.35\linewidth}|}
		\hline
		& \textbf{معتبر (Valid)} & \textbf{نامعتبر (Invalid)} \\
		\hline
		اقدامات پیش‌قراردادی (۱) & ارسال تبلیغات آنلاین برای مشتری که خواهان اطلاعات بیشتر است & \\
		\hline
		اقدامات پیش‌قراردادی (۲) & & بازاریابی مستقیم مبتنی بر پروفایل‌سازی بدون اطلاع موضوع داده \\
		\hline
	\end{tabular}
	\label{tab:17-3-pre-contractual}
\end{table}


% =================================================================
% ادامه بخش ۱۷.۵: از زیربخش ۱۷.۵.۳ تا ۱۷.۵.۶
% =================================================================

\subsubsection{منافع حیاتی موضوع داده}
\label{sec:17-5-3-vital-interests}

این مبنا — منافع حیاتی موضوع داده — حاشیه‌ای و باقی‌مانده است (یعنی زمانی که نمی‌توان به سایر مبانی استناد کرد) \lr{(Art. 29 WP, 2014, p. 20)}. این مورد موقعیت‌های مرگ و زندگیِ موضوع داده را هدف قرار می‌دهد، مانند مقاصد بشردوستانه، نظارت بر همه‌گیری‌ها، و بلایای طبیعی و انسانی. با افزایش گرمایش جهانی و مسائل پناهندگان، این مورد ممکن است در آینده اهمیت بیشتری پیدا کند.

\subsubsection{انجام وظیفه در جهت منافع عمومی یا اعمال اقتدار رسمی محول شده به کنترل‌کننده}
\label{sec:17-5-4-public-task}

نهادهای عمومی خدمات عمومی (مانند آموزش، حمل‌ونقل) ارائه می‌دهند. برای این به‌اصطلاح «وظایف منافع عمومی»، آن‌ها ممکن است نیاز به پردازش داده‌های شخصی داشته باشند. این می‌تواند برای یک وظیفه خاص (مانند راه‌اندازی یک طرح کارت شناسایی الکترونیکی جدید توسط دولت) یا به موجب صلاحیت عمومی آن‌ها باشد (برای مثال، مقامات مالیاتی برای انجام صحیح وظیفه خود، نیاز به پردازش اظهارنامه مالیاتی فرد دارند تا میزان مالیات پرداختی را تعیین کنند) \lr{(Art. 29 WP, 2014, pp. 21–23)}.

با افزایش خصوصی‌سازی خدمات عمومی، مفهوم اقتدار عمومی گسترش یافته تا شامل نهادهایی شود که تابع رژیم‌های ترکیبی حقوق خصوصی-عمومی هستند (مانند شرکت‌های راه‌آهن)، یا در موارد خاص نهادهای کاملاً خصوصی که همچنان یک وظیفه منافع عمومی را اعمال می‌کنند (مانند انجمن حرفه‌ای پزشکی) \lr{(see Art. 29 WP, 2014, p. 22)}.

مقامات عمومی اقتدار و صلاحیت خود را از قانون ملی (یا اتحادیه اروپا) می‌گیرند (یا حتی یک اقدام اداری، که مفهوم قانون نسبتاً بزرگ است). در واقع، یک نهاد عمومی تنها در صورتی می‌تواند وجود داشته باشد که قانونی وجود داشته باشد که آن را (یا صلاحیت خاص آن را) پیش‌بینی کند \lr{(Voigt \& von dem Busche, 2017, pp. 107–108)}.

چنین قانونی باید دارای ویژگی‌های خاصی باشد. به ویژه، قانون باید با قانون حفاظت از داده‌ها منطبق باشد و باید صلاحیت‌هایی را به مقام عمومی اعطا کند که متناسب با هدف دنبال شده باشد \lr{(Voigt \& von dem Busche, 2017, p. 108)}. بنابراین، قانونی که به مقامات مالیاتی قدرت می‌دهد تا حساب‌های رسانه‌های اجتماعی شهروندان را برای یافتن سرنخ‌های فرار مالیاتی «وب‌کاوی» \lr{(web scrape)} کنند، احتمالاً متناسب نیست.

\subsubsection{انطباق با یک تعهد قانونی که کنترل‌کننده تابع آن است}
\label{sec:17-5-5-legal-obligation}

قانون تعهداتی را بر همه ما تحمیل می‌کند. گاهی اوقات، برای انطباق با تعهدات قانونی، کنترل‌کنندگان داده مجبور به پردازش داده‌های شخصی خواهند بود.

این مبنا، که مانند مورد قبلی بر اساس قانون است، با این حال سخت‌گیرانه‌تر است. برای اینکه پردازش برای این مبنا ضروری باشد، کنترل‌کننده نباید هیچ انتخابی جز پردازش داده‌ها داشته باشد (یعنی هیچ اختیار یا صلاحدیدی نداشته باشد) \lr{(Art. 29 WP, 2014, p. 19)}.

این امر بر کیفیت قانونِ مورد بحث پیامدهایی دارد. علاوه بر برآورده کردن تمام الزامات دیده شده در مبنای قبلی، قانونی که منجر به یک تعهد قانونی برای پردازش داده‌های شخصی می‌شود، باید در مورد پردازش داده‌های شخصی که الزام می‌کند نیز به اندازه کافی شفاف باشد \lr{(Art. 29 WP, 2014, p. 19)}.

\subsubsection{منافع مشروع کنترل‌کننده داده یا شخص ثالث}
\label{sec:17-5-6-legitimate-interests}

آخرین مبنایی که کنترل‌کنندگان داده می‌توانند برای آغاز پردازش داده‌های شخصی به آن تکیه کنند، شامل «توازن منافع» است. سوالات مرتبط شامل موارد زیر است: «کدام منافع وزن بیشتری دارند؟» «منافع کنترل‌کننده داده (یا شخص ثالث) یا منافع موضوع داده؟»

بسته به پاسخ این سوال بسیار ذهنی و وابسته به زمینه، پردازش داده‌های شخصی ممکن (یا ناممکن) خواهد بود. این مبنا پیچیده است و نیاز به بررسی بیشتر دارد.

\paragraph{منافع کنترل‌کننده داده: یک نفع مشروع}
\label{sec:17-5-6-1-controller-interest}
\mbox{}\\
برای اینکه یک کنترل‌کننده داده نفعی داشته باشد، به این معنی است که او در پردازش ذینفع است یا منفعتی دارد \lr{(Art. 29 WP, 2014, p. 24)}. چنین نفعی باید به وضوح بیان شود (یعنی برای درک کردن روشن باشد) و باید واقعی و فعلی باشد (نه حدسی).

یعنی نفع باید با فعالیت‌های جاری کنترل‌کننده داده یا آن‌هایی که به طور واقع‌بینانه در آینده بسیار نزدیک انتظار می‌روند، مطابقت داشته باشد (به عبارت دیگر، نمی‌توان شروع به پردازش داده‌ها کرد چون شاید ۲ سال دیگر نفعی داشته باشند که آن را توجیه کند) \lr{(Art. 29 WP, 2014, p. 24)}.

این نفع همچنین می‌تواند متعلق به یک شخص ثالث باشد، که برای بسیاری از شرکت‌هایی که داده‌ها را به نمایندگی از مشتریان خود پردازش می‌کنند، حیاتی است \lr{(Voigt \& von dem Busche, 2017, p. 105)}.

با این حال، مهم‌تر از همه، نفع کنترل‌کننده داده باید «مشروع» باشد. این بدان معناست که باید قانونی باشد (یعنی مطابق با قانون): نه تنها با قانون حفاظت از داده‌ها، بلکه با قوانین به‌طور کلی (شامل قانون‌گذاری، احکام قضایی، کدهای رفتاری)، و فراتر از آن، با اخلاقیات و انتظارات اجتماعی از آنچه پردازش آن مشروع است \lr{(Art. 29 WP, 2014, p. 25)}.

توجه داشته باشید که این زمینه اجتماعی و ارزش‌های اجتماعی می‌توانند در طول زمان تغییر کنند \lr{(Art. 29 WP, 2014, p. 25)}. برای مثال، زمانی که استفاده گسترده از دوربین‌های مداربسته \lr{(CCTVs)} برای مقاصد نظارتی در شهرها در دهه ۱۹۹۰ آغاز شد، دور از آن بود که مشروع تلقی شود \lr{(see, e.g., Coleman \& McCahill, 2011, p. 146)}. با این حال، امروزه همه ما به دوربین‌های مداربسته عادت کرده‌ایم و بحث به سمت اشکال مزاحم‌تر نظارت مانند تشخیص چهره حرکت کرده است.\footnote{برای مثال نگاه کنید به: \lr{https://edps.europa.eu/press-publications/press-news/blog/facial-recognition-solution-search-problem\_en}، آخرین دسترسی ۲۹ ژوئن ۲۰۲۰.}

کارگروه ماده ۲۹ مثال‌های مختلفی از منافعی که مشروع یا نامشروع هستند ارائه می‌دهد \lr{(Art. 29 WP, 2014, p. 25, 63, 68)}:

\vspace{0.3cm}
\noindent
\textbf{نفع مشروع:}
\begin{itemize}
	\item اعمال حق آزادی بیان و/یا اطلاعات توسط روزنامه یا سازمان مردم‌نهاد \lr{(NGO)}
	\item بازاریابی مستقیم متعارف
	\item امنیت شبکه \lr{IT}
\end{itemize}

\vspace{0.3cm}
\noindent
\textbf{نفع نامشروع:}
\begin{itemize}
	\item نظارت بر کارمندان برای تأیید بهره‌وری
	\item ترکیب اطلاعات شخصی در سراسر خدمات وب
\end{itemize}

\paragraph{منافع یا حقوق بنیادین موضوع داده}
\label{sec:17-5-6-2-data-subject-interest}
\mbox{}\\
نفع موضوع داده شامل تمام حقوق و آزادی‌های بنیادین آن‌ها (مانند حریم خصوصی، عدم تبعیض، محاکمه عادلانه) می‌شود و نیازی نیست که برای به رسمیت شناخته شدن، «مشروع» باشد \lr{(Art. 29 WP, 2014, pp. 29–30)}.

بنابراین آستانه پایین‌تر است و حتی در مواردی که موضوع داده به‌طور بالقوه درگیر یک فعالیت غیرقانونی شده است نیز اعمال می‌شود. برای مثال، دانلود غیرقانونی محتوای دارای کپی‌رایت، به خودی خود نظارت بر ترافیک اینترنت موضوع داده را توجیه نمی‌کند \lr{(Art. 29 WP, 2014, pp. 29–30)}. توازن منافع مختلفِ درگیر همچنان باید انجام شود.

\paragraph{توازن منافع}
\label{sec:17-5-6-3-balancing}
\mbox{}\\
برای تعیین اینکه آیا نفع کنترل‌کننده داده به اندازه کافی مشروع است، باید در برابر نفع موضوع داده سنجیده (یا توازن) شود. توازن منافع تعیین می‌کند که کدام نفع وزن بیشتری دارد و بنابراین، آیا عملیات پردازش می‌تواند انجام شود یا خیر \lr{(Art. 29 WP, 2014, p. 30)}. توازن منافع به‌طور ملموس از طریق تعدادی از گام‌ها انجام می‌شود که در زیر توضیح داده شده‌اند.

\vspace{0.3cm}
\noindent
\textbf{گام ۱: توصیف منافع \lr{(Qualify the Interests)}}

اولین گام توصیف منافع است. آیا آن‌ها بسیار جدی و الزام‌آور هستند، یا صرفاً جزئی؟ تا آنجا که به کنترل‌کننده داده مربوط می‌شود، می‌توان به طبقه‌بندی نشان داده شده در جدول ۱۷.۴ مراجعه کرد.

تا آنجا که به موضوع داده مربوط می‌شود، نفع آن‌ها همیشه بالاست زیرا پردازش داده‌های شخصی بنا به تعریف شامل حقوق بنیادین آن‌ها می‌شود (نگاه کنید به مقدمه این فصل). به همین دلیل است که باید نگاهی به تأثیر بالقوه‌ای داشت که عملیات پردازش برنامه‌ریزی شده بر منافع و حقوق آن‌ها خواهد گذاشت (گام دوم).

\begin{table}[h!]
	\centering
	\caption{توصیف منافع \lr{(Source: Compiled by author, building upon Art. 29 WP, 2014, pp. 34–36)}}
	\vspace{0.2cm}
	\begin{tabular}{|l|l|l|}
		\hline
		\textbf{دسته‌بندی نفع} & \textbf{جدیت} & \textbf{مثال} \\
		\hline
		حق بنیادین & بسیار زیاد & روزنامه‌نگاری تحقیقی \\
		\hline
		منافع عمومی & متوسط & تحقیقات پزشکی \\
		\hline
		نفع شخصی & کم & سود خصوصی \\
		\hline
	\end{tabular}
	\label{tab:17-4-qualification-interests}
\end{table}

\vspace{0.3cm}
\noindent
\textbf{گام ۲: تأثیر(ات) بر موضوع داده}

یک تأثیر می‌تواند به عنوان «روش‌های مختلفی که در آن یک فرد ممکن است تحت تأثیر پردازش داده‌های شخصی خود قرار گیرد — چه مثبت و چه منفی» تعریف شود \lr{(Art. 29 WP, 2014 p. 37)}. تأثیر می‌تواند ماهیت متفاوتی داشته باشد. آن‌ها می‌توانند عاطفی/اخلاقی (مانند ترس، پریشانی، شهرت)، مادی (مانند زیان مالی، تبعیض شغلی یا قیمتی، فیزیکی)، سیاسی (اثر دلسردکننده، خودسانسوری) و غیره باشند \lr{(see, Art. 29 WP, 2014, p. 37)}.

به خودی خود، درک این تأثیرات ممکن است دشوار به نظر برسد. بنابراین می‌توان به تعدادی از عوامل نگاه کرد که ارزیابی آن‌ها را روان‌تر می‌کند.

\vspace{0.3cm}
\noindent
\textbf{گام ۳: عوامل ارزیابی تأثیرات}

برای تعیین بهتر اینکه تأثیر چیست، می‌توان به عوامل ریسک زیر نگاه کرد. می‌توان به ماهیت یا نوع داده‌های شخصیِ در حال پردازش نگاه کرد \lr{(Art. 29 WP, 2014, p. 38)}. هر چه داده‌ها حساس‌تر باشند، تأثیر بیشتر است. داده‌های حساس می‌توانند به دسته‌های خاص داده‌های مندرج در \lr{GDPR} (داده‌های مربوط به سلامت، وابستگی سیاسی و غیره) اشاره داشته باشند، اما همچنین می‌توانند در معنای عمومی حساس باشند (مانند داده‌های کودکان، داده‌های موقعیت مکانی دقیق). برعکس، برخی داده‌ها می‌توانند کمتر حساس تلقی شوند، مانند داده‌هایی که موضوع داده قبلاً آن‌ها را به صورت عمومی در دسترس قرار داده است (مثلاً پروفایل حرفه‌ای آنلاین).

عامل دیگر، نوع پردازشِ درگیر است \lr{(Art. 29 WP, 2014, p. 39)}. این شامل تنوعی از عوامل مانند تعداد موضوعات داده، مقدار داده‌ها، یا تنوع داده‌های پردازش شده است. همچنین شامل تعداد کنترل‌کنندگان و/یا پردازشگرانی است که داده‌ها با آن‌ها به اشتراک گذاشته می‌شود. در نهایت، چه نوع عملیات پردازشی روی داده‌ها انجام می‌شود؟ آیا مشمول عملیات ساده و نسبتاً خوش‌خیم (مانند جمع‌آوری و اشتراک‌گذاری) است، یا در پایگاه‌های داده با ابعاد بالا ادغام می‌شود (بنابراین با سایر داده‌ها ترکیب می‌شود) و بیشتر تحت تحلیل‌های پیشرفته قرار می‌گیرد؟

عامل دیگر، احتمال \lr{(likelihood)} است. از یک سو، یک تأثیر بسیار محتمل نشان‌دهنده تأثیر بالاست. از سوی دیگر، یک تأثیر بسیار نامطمئن نیز می‌تواند نشان‌دهنده تأثیر بالا باشد (چون ما سرنخ کمی داریم که آیا اتفاق می‌افتد یا خیر) \lr{(Art. 29 WP, 2014, p. 38)}.

در نهایت، آخرین نوع عامل، «انتظارات معقول» موضوع داده است \lr{(Art. 29 WP, 2014, p. 40)}. این یک مفهوم مهم در قانون حفاظت از داده‌ها است. این به آنچه یک موضوع داده می‌تواند به‌طور معقول در یک زمینه خاص درباره آنچه برای داده‌هایش اتفاق می‌افتد انتظار داشته باشد، اشاره دارد. یعنی، آیا اگر داده‌هایشان پردازش شود یا تحت یک عملیات پردازش خاص قرار گیرد، متعجب خواهند شد \lr{(Dehon \& Carey, 2018, p. 59)}؟

به عبارت دیگر، این به زمینه از دیدگاه موضوع داده اشاره دارد. برای تعیین انتظارات معقول موضوع داده، می‌توان به زیر-عوامل زیر نگاه کرد. رابطه، موازنه قدرت، بین موضوع داده و کنترل‌کننده داده چیست؟ آیا آن‌ها در یک رابطه استخدامی درگیر هستند؟ آیا کنترل‌کننده داده یک مقام عمومی است؟ آیا کنترل‌کننده داده خدماتی را در یک وضعیت شبه‌انحصاری ارائه می‌دهد (مثلاً سرویس شبکه‌های اجتماعی محبوب)، یا برعکس یک شرکت کوچک با قدرت چانه‌زنی بسیار کم است؟ آیا موضوع داده خود آسیب‌پذیر است (مثلاً کودک، بیمار روانی، سالمند)؟ همچنین می‌توان به تعهدات قانونی یا قراردادی موجود بین موضوع داده و کنترل‌کننده داده نگاه کرد: پزشکان یا وکلا مشمول تعهدات محرمانگی هستند، و یک قرارداد نیز ممکن است وظایف محرمانگی مشابهی را پیش‌بینی کند. به طور کلی، هر چه زمینه جمع‌آوری خاص‌تر و محدودتر باشد، انتظارات معقول موضوع داده محدودتر است \lr{(Art. 29 WP, 2014, pp. 40–41)}.

\vspace{0.3cm}
\noindent
\textbf{گام ۴: توازن موقت \lr{(Provisional Balance)}}

در این نقطه، می‌توان یک توازن اولیه بین نفع مشروع کنترل‌کننده داده و تأثیرات بر منافع و حقوق بنیادین موضوع داده ایجاد کرد \lr{(Art. 29 WP, 2014, p. 41)}. عملِ توازن کردن به خودی خود — مانند علم داده — بیشتر هنر است تا علم. هیچ «قاعده عینی» وجود ندارد که بتواند کنترل‌کننده داده را راهنمایی کند تا تعیین کند کدام عناصر توازن وزن سنگین‌تری دارند.

این یک تصمیم زمینه‌ای و موردی است که باید بر اساس عوامل توصیف شده در بالا اتخاذ شود. با توجه به عوامل مختلفِ درگیر، باید روشن باشد که همه تأثیرات وزن یکسانی ندارند. برخی موارد واضح هستند، در حالی که برخی دیگر ممکن است بر نوعی تصمیم‌گیری «قاعده سرانگشتی» \lr{(rule of thumb)} تکیه کنند، با علم به اینکه شخص دیگری ممکن است در صورت قرار گرفتن در همان موقعیت، راه حل مخالف را انتخاب کند. به همین دلیل ارائه توضیح تصمیم و نگهداری سوابق آن حیاتی است \lr{(Art. 29 WP, 2014, p. 43)}. در هر صورت، در صورت شک، توصیه می‌شود که به نفع موضوع داده توازن برقرار شود \lr{(Dehon \& Carey, 2018, p. 58)}.

\vspace{0.3cm}
\noindent
\textbf{گام ۵: پادمان‌های اضافی \lr{(Additional Safeguards)}}

همان‌طور که ذکر شد، توازن برقرار شده تنها موقتی است. این بدان دلیل است که اگر توازن به نفع موضوع داده متمایل شود، هنوز امکان بهبود وضعیت با توسل به به‌اصطلاح «پادمان‌ها» وجود دارد. پادمان‌ها می‌توانند به عنوان مکانیسم‌های قانونی اضافی درک شوند که حفاظت بیشتری برای موضوع داده فراهم می‌کنند، و با انجام این کار، ممکن است کمک کنند تا توازن به نفع کنترل‌کننده داده متمایل شود \lr{(Art. 29 WP, 2014, pp. 41–42)}. این پادمان‌های اضافی نباید به عنوان یک راه حل «معجزه‌آسا» دیده شوند. هر چه تأثیر سنگین‌تر باشد، به پادمان‌های بیشتری نیاز خواهید داشت، و این احتمال وجود دارد که آن‌ها نتوانند توازن را دوباره به نفع کنترل‌کننده داده متمایل کنند \lr{(Art. 29 WP, 2014, p. 42)}.

برخی از این پادمان‌ها هم‌اکنون بخشی از \lr{GDPR} هستند (و در ادامه بررسی خواهند شد). آن‌ها شامل یک کاربرد «تقویت‌شده» از مقررات موجود هستند: برای مثال، ارائه شفافیت بیشتر از حد معمول برای روشن کردن این موضوع برای موضوع داده که چرا مبنای نفع مشروع انتخاب شده است، چگونه تأثیرات ارزیابی و توازن شده‌اند و غیره. امکان دیگر، کاهش مقدار داده‌های جمع‌آوری شده فراتر از آنچه تجویز شده است برای کاهش تأثیر بر موضوع داده است. امکان دیگر، نامستعارسازی \lr{(pseudonymisation)} داده‌هاست \lr{(Art. 29 WP, 2014, p. 42)}.

سایر پادمان‌ها به عنوان بخشی از \lr{GDPR} نیستند. آن‌ها برای مثال شامل امکان گنجاندن یک مکانیسم \lr{opt-out} بی قید و شرط (موضوع داده عملیات پردازش را بدون هیچ شرطی پایان می‌دهد)، یا ایجاد بندهای محرمانگی (کنترل‌کننده داده، داده‌ها را با دیگران به اشتراک نخواهد گذاشت) هستند \lr{(Art. 29 WP, 2014, pp. 42–43)}.

\vspace{0.3cm}
\noindent
\textbf{گام ۶: توازن نهایی \lr{(Final Balance)}}

در این نقطه، یک توازن نهایی برقرار می‌شود. این از همان اصول توازن موقت پیروی می‌کند و تعیین خواهد کرد که آیا پادمان‌ها تأثیرات را به اندازه کافی کاهش داده‌اند تا توازن اکنون به نفع کنترل‌کننده داده متمایل شود یا خیر.

% =================================================================
% بخش ۱۷.۶: ماده ۵ GDPR
% =================================================================

\subsection{ماده ۵ \lr{GDPR}: اصولی که باید در پردازش داده‌ها اعمال شوند}
\label{sec:17-6-art5-principles}

زمانی که مبنای مناسبی برای پردازش پیدا شد، آنگاه شروع پردازش داده‌های شخصی امکان‌پذیر است. اینجاست که ماده ۵ \lr{GDPR} وارد عمل می‌شود. این ماده حاوی تعدادی از اصول است که اگر قرار است پردازش قانونی باشد، باید رعایت شوند.

\subsubsection{اصل محدودیت هدف \lr{(Purpose Limitation)}}
\label{sec:17-6-1-purpose-limitation}

ماده ۵(۱)(ب) \lr{GDPR} بیان می‌کند که داده‌ها باید تنها برای اهداف مشخص، صریح و مشروع جمع‌آوری شوند و نباید به هیچ وجهی که با آن اهداف ناسازگار است، پردازش شوند. این اصل را می‌توان به دو نوع الزام تجزیه کرد.

اولین نوع الزام مربوط به «هدف اولیه» است: باید مشخص، صریح و مشروع باشد («تعیین هدف»).
دومین نوع الزام مربوط به پردازش داده‌های جمع‌آوری شده قبلی برای یک «هدف جدید» است: این هدف جدید باید با هدف اولیه جمع‌آوری سازگار باشد («محدودیت هدف به معنای دقیق کلمه»).

\paragraph{۱۷.۶.۱.۱ تعیین هدف: چرا؟}
شروع عملیات پردازش با تعیین و مشخص کردن هدف آن ضروری است، زیرا در غیر این صورت به این معنی خواهد بود که ما می‌توانیم داده‌ها را بدون دلیل پردازش کنیم. پردازش همیشه باید با توجه به یک هدف، ضروری باشد \lr{(Art. 29 WP, 2013, p. 11)}. همچنین، تعدادی از الزامات دیگر بر این واقعیت تکیه دارند که هدف به خوبی تعریف شده باشد (در ادامه ببینید).

\paragraph{۱۷.۶.۱.۲ هدف مشخص \lr{(Specific Purpose)}}
اولین عنصر الزام تعیین هدف این است که هدف به وضوح و به‌طور مشخص شناسایی شود. این بدان معناست که هدف به گونه‌ای تعریف شود که به اندازه کافی خاص باشد، با سطح کافی از جزئیات، تا بتوان تعیین کرد چه عملیات پردازشی تحت آن قرار می‌گیرد \lr{(Art. 29 WP, 2013, p. 15)}. مثالی از هر دو هدف مبهم و مشخص را می‌توان در جدول ۱۷.۵ یافت.

مشخص کردن هدف ممکن است مستلزم ارائه اطلاعات اضافی مانند نوع عملیات پردازش، مدت زمان آن، یا نوع داده‌های مورد بحث باشد \lr{(Art. 29 WP, 2013, p. 16)}.

یک مسئله کلیدی، مسئله «اهداف چتری» \lr{(umbrella purposes)} است. این به موقعیت‌هایی اشاره دارد که در آن تعدادی از اهداف تحت یک هدفِ گسترده‌ترِ واحد گروه‌بندی می‌شوند. این کار اگر عملیات پردازش مختلف به هم مرتبط باشند می‌تواند منطقی باشد (اگرچه جزئیات کافی باید برای هر یک از آن‌ها ارائه شود). آنچه باید اجتناب شود، استفاده از یک هدف چتری برای توجیه اهداف مختلفی است که به هم مرتبط نیستند \lr{(Art. 29 WP, 2013, p. 16)}.

% جدول ۱۷.۵
\begin{table}[h!]
	\centering
	\caption{هدف مبهم و مشخص \lr{(Source: Art. 29 WP, 2018b, p. 9)}}
	\vspace{0.2cm}
	\begin{tabular}{|p{0.45\linewidth}|p{0.45\linewidth}|}
		\hline
		\textbf{هدف مبهم} & \textbf{هدف مشخص} \\
		\hline
		«بهبود تجربه کاربران» & «ما تاریخچه خرید شما را با اشخاص ثالث به اشتراک می‌گذاریم تا محتوای متناسب برای خریدهای آینده را به شما ارائه دهیم» \\
		\hline
	\end{tabular}
	\label{tab:17-5-vague-specific}
\end{table}

\paragraph{۱۷.۶.۱.۳ هدف صریح \lr{(Explicit Purpose)}}
صریح بودن هدف به این معنی است که باید به وضوح آشکار، توضیح داده شده، یا به شکلی قابل فهم بیان شود \lr{(Art. 29 WP, 2013, p. 17)}. در حالی که الزامِ مشخص بودن هدف از منظر کنترل‌کننده داده ساخته می‌شود (آن‌ها باید آن را مشخص کنند)، این الزام از منظر موضوع داده ساخته می‌شود: موضوع داده نباید در درک اینکه هدف چیست مشکلی داشته باشد \lr{(Art. 29 WP, 2013, p. 17)}. به همین دلیل، این الزام می‌تواند به دو زیر-الزام تجزیه شود.

اول از همه، هدف باید «به آسانی قابل درک» باشد \lr{(Art. 29 WP, 2013, p. 17)}. این الزام مربوط به کیفیت زبان استفاده شده است که باید توسط همه (تمام موضوعات داده بالقوه، مقامات حفاظت از داده و غیره) قابل درک باشد. کنترل‌کنندگان داده باید این واقعیت را در نظر بگیرند که ممکن است موضوعات داده متفاوتی با نیازهای مختلف داشته باشند (مثلاً کودکان، سالمندان، افراد با مهارت‌های سواد مختلف). به منظور اطمینان از اینکه زبان روشن و بدون ابهام است، کنترل‌کننده داده باید اطمینان حاصل کند که جزئیات کافی وجود دارد (اما نه بیش از حد) و زبان استفاده شده ساده و واضح است. مثال کاملِ «بد»، شرایط و ضوابطی است که بیش از حد طولانی هستند و بر اصطلاحات حقوقی پیچیده تکیه دارند \lr{(Art. 29 WP, 2013, p. 17)}.

دوم، هدف باید «به آسانی قابل دسترسی» باشد \lr{(Art. 29 WP, 2013, p. 18)}. این الزام مربوط به سهولتی است که موضوعات داده می‌توانند اطلاعات را پیدا کنند، که باید روشن و متمایز باشد. با در نظر گرفتن مثال شرایط و ضوابط یک سرویس، این بدان معناست که موضوع داده نباید در یافتن اطلاعاتی که هدف را صریح می‌کند (هایلایت شده، پررنگ، لینک مشخص و غیره) مشکلی داشته باشد \lr{(Art. 29 WP, 2013, p. 18, 51–55)}.

\paragraph{۱۷.۶.۱.۴ هدف مشروع \lr{(Legitimate Purpose)}}
آخرین عنصر الزام تعیین هدف این است که هدف باید مشروع باشد. این بدان معناست که هدف باید قانونی باشد (یعنی مطابق با قانون)، نه تنها با قانون حفاظت از داده‌ها، بلکه با قوانین به‌طور کلی (شامل قانون‌گذاری، احکام قضایی، کدهای رفتاری). فراتر از این، باید با اخلاقیات و هنجارهای اجتماعی که زمینه‌ای هستند و می‌توانند در طول زمان تغییر کنند، منطبق باشد \lr{(Art. 29 WP, 2013, pp. 19–20)}.

\paragraph{۱۷.۶.۱.۵ هدف متفاوت \lr{(Different Purpose)}}
این اصل مربوط به وضعیتی است که داده‌ها برای یک هدف جمع‌آوری می‌شوند، اما کنترل‌کننده داده سپس می‌خواهد از آن برای هدف متفاوتی استفاده کند (مثلاً هدف دیگری که در زمان جمع‌آوری در نظر گرفته نشده بود). به‌طور معمول، اگر هدف جدید در هدف اصلی گنجانده نشده باشد، این کار نباید امکان‌پذیر باشد («محدودیت هدف به معنای دقیق کلمه»).

با این حال، اصل محدودیت هدف می‌گوید که چنین پردازشِ بعدی تا زمانی که این هدف جدید با هدف جمع‌آوری «سازگار» باشد، امکان‌پذیر خواهد بود. این بدان معناست که کنترل‌کننده داده نیاز دارد تا یک «آزمون سازگاری» انجام دهد. ایده اصلی نگاه کردن به رابطه بین اهداف است. هر چه رابطه نزدیک‌تر باشد، شانس سازگار بودن اهداف بیشتر است \lr{(Art. 29 WP, 2013, p. 21)}.

آزمون سازگاری در تعدادی از گام‌ها انجام می‌شود (همچنین نگاه کنید به ماده ۶(۴) \lr{GDPR}). اولین گام تعیین این است که آیا پیوند آشکاری بین اهداف وجود دارد یا خیر. این مورد زمانی صادق است که همپوشانی بین اهداف وجود داشته باشد: برای مثال، اگر پردازش بعدی کم و بیش در اهداف اولیه مستتر بوده باشد، یا اگر پیوندی (حتی جزئی) بین اهداف وجود داشته باشد \lr{(Art. 29 WP, 2013, p. 22)}. اگر پیوند آشکاری وجود نداشته باشد، آزمون دقیق‌تری باید انجام شود. همان‌طور که در جدول ۱۷.۶ نشان داده شده است، این آزمون شبیه به آزمون توازنی است که تحت مبنای نفع مشروع انجام می‌شود (نگاه کنید به بخش ۱۷.۵.۶).

% جدول ۱۷.۶
\begin{table}[h!]
	\centering
	\caption{مقایسه آزمون‌های توازن \lr{(Source: Compiled by author)}}
	\vspace{0.2cm}
	\small
	\begin{tabular}{|p{0.48\linewidth}|p{0.48\linewidth}|}
		\hline
		\textbf{گام‌های توازن منافع (بخش ۱۷.۵.۶)} & \textbf{گام‌های ارزیابی سازگاری اهداف} \\
		\hline
		۱. ارزیابی تأثیر بر موضوع داده: \newline (الف) لیست تأثیر بر موضوع داده \newline (ب) عوامل ارزیابی تأثیر: \newline -- نوع داده \newline -- نوع پردازش \newline -- احتمال تأثیرات \newline -- انتظارات معقول موضوع داده 
		& 
		۱. ارزیابی سازگاری بین اهداف: \newline (الف) پیوند بین اهداف \newline -- آشکار: نیازی به ادامه نیست \newline -- غیرآشکار: نیاز به بررسی سایر گام‌ها \newline (ب) انتظارات معقول موضوع داده \newline (ج) لیست تأثیر بر موضوع داده \newline (د) عوامل ارزیابی تأثیر: \newline -- نوع داده \newline -- نوع پردازش \newline -- احتمال تأثیرات \\
		\hline
		۲. توازن موقت & ۲. توازن موقت \\
		\hline
		۳. پادمان‌های اضافی & ۳. پادمان‌های اضافی \\
		\hline
		۴. توازن نهایی & ۴. توازن نهایی \\
		\hline
	\end{tabular}
	\label{tab:17-6-balancing-tests}
\end{table}

ارزیابی سازگاری تقریباً مشابه آزمون توازن منافع است. علاوه بر تعیین وجود یک پیوند آشکار بین اهداف، ترتیب گام‌ها نیز در ارزیابی سازگاری کمی تغییر می‌کند. این به دلیل تغییر موضوع ارزیابی است: به جای ارزیابی تأثیر بر موضوعات داده، فرد باید سازگاری بین اهداف را ارزیابی کند.

یکی از راه‌های ارزیابی چنین سازگاری، نگاه کردن به انتظارات معقول موضوع داده در زمینه است \lr{(Art. 29 WP 2013, pp. 24–25)}. گام دوم نگاه کردن و لیست کردن تأثیرات بر موضوع داده خواهد بود \lr{(Art. 29 WP, 2013, pp. 25–26)}. این تأثیرات می‌توانند از طریق همان عوامل (یعنی نوع داده، نوع پردازش، احتمال تأثیر)، منهای انتظارات معقول موضوع داده (که قبلاً بررسی شد)، بهتر ارزیابی شوند \lr{(see, Art. 29 WP, 2013, p. 26)}.

در این نقطه، ارزیابی سازگاری انجام می‌شود و می‌توان یک توازن موقت نیز بین دو هدف برقرار کرد: آیا دو هدف به اندازه کافی سازگار هستند که پردازش بعدی بتواند انجام شود \lr{(Art. 29 WP, 2013, p. 26)}؟ دوباره به خاطر داشته باشید که چیزها در یک «طیف» قرار دارند و این یک تصمیم «قاعده سرانگشتی» است.

گام بعدی البته استفاده از پادمان‌های اضافی است که می‌تواند تأثیر بر موضوع داده را کاهش دهد. همان نکات مربوط به مبنای نفع مشروع اعمال می‌شود، با در نظر گرفتن اینکه آنچه مناسب‌ترین پادمان در نظر گرفته می‌شود، بسته به زمینه تغییر خواهد کرد \lr{(Art. 29 WP, 2013, pp. 26–27)}.

در این نقطه، یک توازن نهایی برقرار می‌شود. این از همان اصول توازن موقت پیروی می‌کند و تعیین خواهد کرد که آیا پادمان‌ها تأثیرات را به اندازه کافی کاهش داده‌اند تا توازن اکنون به نفع پردازش بعدی متمایل شود یا خیر.

اگر توازن به نفع پردازشِ بعدی متمایل شود، آنگاه پردازش می‌تواند انجام شود. در صورتی که توازن علیه پردازشِ بعدی باشد، دومی نمی‌تواند انجام شود \lr{(Art. 29 WP, 2013, p. 36)}. این بدان معناست که یک مبنای جدید برای پردازش باید پیدا شود.

\subsubsection{کمینه‌سازی داده‌ها \lr{(Data Minimisation)}}
\label{sec:17-6-2-data-minimisation}

ماده ۵(۱)(ج) \lr{GDPR} مقرر می‌دارد که پردازش داده‌های شخصی باید «کافی، مرتبط و محدود به آنچه ضروری است» در رابطه با اهداف پردازش باشد. به عبارت دیگر، کنترل‌کننده داده باید پردازش داده‌ها را تا حد امکان به گونه‌ای به حداقل برساند که همچنان آن‌ها را قادر به دستیابی به هدف پردازش سازد \lr{(Voigt \& von dem Busche, 2017, p. 90)}.

راه‌های مختلفی برای به حداقل رساندن پردازش داده‌ها وجود دارد. می‌توان مقدار داده‌های اولیه جمع‌آوری شده را محدود کرد، نوع داده‌ها را محدود کرد، تعداد موضوعات داده را محدود کرد، تعداد افرادی که به داده‌ها دسترسی دارند را محدود کرد، نوع عملیات پردازشی انجام شده روی داده‌ها را محدود کرد، و غیره \lr{(also see Carey, 2018a, pp. 35–36)}.

\subsubsection{محدودیت ذخیره‌سازی \lr{(Storage Limitation)}}
\label{sec:17-6-3-storage-limitation}

ماده ۵(۱)(هـ) \lr{GDPR} مقرر می‌دارد که داده‌های شخصی نباید طولانی‌تر از حد لازم برای هدف پردازش نگهداری شوند. این اصل را می‌توان به عنوان ادامه اصل کمینه‌سازی داده‌ها در مورد مدت زمان ذخیره‌سازی داده‌ها در نظر گرفت. نکته این است که به محض اینکه هدفی که داده‌ها برای آن جمع‌آوری شده‌اند محقق شد، داده‌ها نباید بیشتر نگه داشته شوند. آن‌ها می‌توانند حذف/نابود شوند یا ناشناس‌سازی شوند (در این مورد، مطمئن شوید که ناشناس‌سازی غیرقابل برگشت است).

پیش‌بینی اینکه چه مدت لازم است داده‌ها ذخیره شوند ممکن است دشوار باشد. برای جلوگیری از نگهداری داده‌ها «محض احتیاط» \lr{(just in case)}، توصیه می‌شود یک «سیاست ذخیره‌سازی» ایجاد کنید. این سیاست محدودیت‌های زمانی برای ذخیره‌سازی را تعیین می‌کند و این محدودیت‌ها تابع بازنگری دوره‌ای هستند (مقدمه ۳۹، \lr{GDPR}؛ همچنین نگاه کنید به \lr{Carey, 2018a, p. 38}).

\subsubsection{تعهدات اضافی}
\label{sec:17-6-4-additional-obligations}

به عنوان راهی برای نتیجه‌گیری این مرور کلی بر ماده ۵ \lr{GDPR}، می‌توان به طور خلاصه به اصول باقی‌مانده اشاره کرد.

\paragraph{۱۷.۶.۴.۱ دقت داده‌ها \lr{(Data Accuracy)}}
طبق ماده ۵(۱)(د) \lr{GDPR}، کنترل‌کنندگان داده باید اطمینان حاصل کنند که داده‌ها دقیق هستند و در صورت لزوم به‌روز نگه داشته می‌شوند. این برای اطمینان از این است که داده‌های در اختیار کنترل‌کننده داده به درستی واقعیتِ موضوع داده را منعکس می‌کنند \lr{(also see Voigt \& von dem Busche, 2017, p. 91)}.

\paragraph{۱۷.۶.۴.۲ قانونی بودن، انصاف و شفافیت}
طبق ماده ۵(۱)(الف) \lr{GDPR}، پردازش تنها در صورتی می‌تواند انجام شود که در معنای عمومی قانونی باشد و اگر با قانون حفاظت از داده‌ها منطبق باشد \lr{(see Carey, 2018a, p. 33)}. علاوه بر این، الزام انصاف مستلزم منصف بودن با موضوع داده است، از جمله با در نظر گرفتن انتظارات معقول آن‌ها در مورد آنچه پردازش مستلزم آن است \lr{(see Dehon \& Carey, 2018, p. 43)}.

اصل شفافیت دو جنبه دارد \lr{(Dehon \& Carey, 2018, p. 44)}. از یک سو، هدف آن اطمینان از این است که موضوع داده به اندازه کافی در مورد پردازش مطلع شده است و بنابراین نیاز به ارائه حداقل اطلاعات به آن‌ها در مورد هویت کنترل‌کننده داده، هدف پردازش، نوع داده‌های جمع‌آوری شده و غیره دارد. از سوی دیگر، مربوط به کیفیت اطلاعات است که باید هم به آسانی قابل درک و هم به آسانی قابل دسترسی باشد (همچنین نگاه کنید به بخش‌های ۱۷.۵.۱ و ۱۷.۶.۱ این فصل).

\paragraph{۱۷.۶.۴.۳ یکپارچگی و محرمانگی}
طبق ماده ۵(۱)(و) \lr{GDPR}، کنترل‌کنندگان داده باید سطح مناسبی از امنیت داده‌هایی را که پردازش می‌کنند تضمین کنند، که شامل حفاظت در برابر پردازش غیرمجاز یا غیرقانونی، و در برابر از دست دادن تصادفی، نابودی یا آسیب است \lr{(Voigt \& von dem Busche, 2017, p. 92)}.

% =================================================================
% نتیجه‌گیری
% =================================================================

\vspace{0.8cm}
\noindent
\fcolorbox{black}{gray!15}{%
	\begin{minipage}{\dimexpr\linewidth-2\fboxsep-2\fboxrule}
		\vspace{0.3cm}
		\begin{center}
			\textbf{\Large نتیجه‌گیری}
		\end{center}
		\vspace{0.2cm}
		
		برای اینکه از نظر اجتماعی مسئول باشیم، به نظر می‌رسد بسیار مهم است که علم داده با قانون حفاظت از داده‌ها منطبق باشد. برخلاف حقوق و ارزش‌های گسترده مانند حریم خصوصی که گاهی تعیین حدود آن‌ها دشوار است، حفاظت از داده‌ها دارای تعدادی قوانین و اصول بسیار مشخص است.
		
		این فصل نشان داده است که مفهوم داده‌های شخصی گسترده‌تر از آن چیزی است که معمولاً تصور می‌شود. همچنین نشان داده است که آنچه به عنوان کنترل‌کننده داده یا پردازشگر داده نامیده می‌شود، یک مفهوم فنی است که لزوماً با درک عامیانه‌ای که ممکن است از آن‌ها داشته باشیم مطابقت ندارد.
		
		همچنین مبانی اجازه دهنده پردازش داده‌های شخصی را به تفصیل بررسی کرده است. توجه ویژه‌ای باید به آنچه یک رضایت معتبر را تشکیل می‌دهد، مبذول شود. این کار آنقدر که ممکن است باور داشته باشیم آسان نیست. به همان اندازه، انجام توازن منافع تحت مبنای نفع مشروع، تمرین ظریفی باقی می‌ماند که می‌تواند مورد مناقشه قرار گیرد. چنین توازنی همچنین در تعیین اینکه چه چیزی یک پردازشِ بعدیِ قابل قبول برای یک هدف متفاوت را تشکیل می‌دهد، یافت می‌شود. این به ما یادآوری می‌کند که تعریف مناسب یک هدف، کلید قانون حفاظت از داده‌ها است زیرا اجازه می‌دهد تا ضرورت و تناسب عملیات پردازش در نظر گرفته شده ارزیابی شود، که خود کلید یک تمرین مسئولانه علم داده است.
		\vspace{0.3cm}
	\end{minipage}
}

% =================================================================
% پرسش‌ها و پاسخ‌ها (ترجمه شده)
% =================================================================
\vspace{1cm}
\section*{پرسش‌ها و پاسخ‌ها}
\addcontentsline{toc}{section}{پرسش‌ها و پاسخ‌ها}

\noindent \textbf{\large ؟ پرسش‌ها}
\begin{enumerate}
	\setlength\itemsep{0.5em}
	\item سه روشی که اطلاعات می‌تواند به موضوع داده مرتبط شود چیست؟
	\item دو معیاری که می‌تواند کسی را به عنوان کنترل‌کننده داده تعیین کند چیست؟
	\item چه الزامی برای تمام مبانی پردازش به جز «رضایت» اعمال می‌شود؟
	\item چرا مشخص کردن هدف عملیات پردازش مهم است؟
	\item ارتباط بین اصول «کمینه‌سازی داده‌ها» و «محدودیت ذخیره‌سازی» چیست؟
\end{enumerate}

\vspace{0.5cm}
\noindent \textbf{\large $\checkmark$ پاسخ‌ها}

\vspace{0.3cm}
\noindent \textbf{\textit{مثال ۱: سوالات کلیدی (پاسخ به کادر ابتدای فصل)}}

اگر شرکت \lr{X} تنها یک هدف پردازش داشته باشد، (فروش داده‌ها) به معنای «پردازش بیشتر برای هدفی متفاوت» است. بنابراین باید آزمون سازگاری انجام شود.
با توجه به فقدان پیوند آشکار بین اهداف، باید به موارد زیر نگاه کرد: انتظارات معقول موضوع داده (هیچ انتظار این‌چنینی وجود ندارد)، تأثیرات بر موضوع داده (زیاد: مداخله در ترجیحات رأی‌دهی و عقاید سیاسی)، عوامل ارزیابی تأثیر (داده‌های بسیار حساس، ایجاد پروفایل، انتقال به اشخاص ثالث) و پادمان‌ها (هیچ موردی ذکر نشده است). بنابراین، این پردازش \textbf{غیرقانونی} است.

\vspace{0.3cm}
\noindent \textbf{\textit{پاسخ سوالات بالا}}
\begin{enumerate}
	\setlength\itemsep{0.5em}
	\item اطلاعات می‌تواند از نظر محتوا، هدف، یا نتیجه (که به عنوان تأثیر نیز شناخته می‌شود) به موضوع داده مرتبط باشد.
	\item کنترل‌کننده داده بازیگری است که «هدف» و/یا «ابزارهای ضروری» پردازش را تعیین می‌کند. تحقق یکی از این شروط برای واجد شرایط شدن به عنوان کنترل‌کننده داده کافی است (که در این صورت به احتمال زیاد وضعیت کنترل‌کنندگی مشترک است).
	\item «ضرورت» پردازش باید تعیین شود.
	\item اگر هدفی وجود نداشته باشد (یا به خوبی تعریف نشده باشد)، بدین معناست که ما می‌توانیم داده‌ها را برای هر دلیلی که می‌خواهیم و بدون هیچ محدودیتی پردازش کنیم. همچنین، تعدادی از الزامات کلیدی برای ارزیابی کفایت، ارتباط یا ضرورت پردازش تنها در صورتی قابل رعایت هستند که هدف به خوبی تعریف شده باشد (مانند ضرورت، کمینه‌سازی داده‌ها، محدودیت ذخیره‌سازی).
	\item اصل محدودیت ذخیره‌سازی می‌تواند به عنوان کاربرد اصل کمینه‌سازی داده‌ها در مسئله «مدت زمان» ذخیره‌سازی داده‌ها درک شود.
\end{enumerate}

% =================================================================
% پیام‌های کلیدی (Take-Home Message) - ترجمه شده
% =================================================================
\vspace{0.8cm}
\noindent
\fcolorbox{black}{gray!15}{%
	\begin{minipage}{\dimexpr\linewidth-2\fboxsep-2\fboxrule}
		\vspace{0.3cm}
		\centering \textbf{\large پیام‌های کلیدی فصل}
		\vspace{0.2cm}
		\begin{itemize}
			\setlength\itemsep{0.5em}
			\item[\textbf{--}] داده‌های شخصی مفهوم گسترده‌ای است که اکثر داده‌های پردازش شده در فناوری‌های پردازش داده امروزی را در بر می‌گیرد.
			\item[\textbf{--}] تمایز بین یک کنترل‌کننده داده و یک پردازشگر داده می‌تواند دشوار و فریبنده باشد.
			\item[\textbf{--}] برای شروع پردازش داده‌ها، فرد بین شش مبنای مختلف حق انتخاب دارد؛ با این حال، حتماً «یک» مبنا باید انتخاب شود.
			\item[\textbf{--}] هنگام پردازش داده‌ها، تمام مفاد ماده ۵ مقررات \lr{GDPR} باید رعایت شوند.
		\end{itemize}
		\vspace{0.2cm}
	\end{minipage}
}

% =================================================================
% منابع (انگلیسی)
% =================================================================
\vspace{1cm}
\section*{منابع}
\addcontentsline{toc}{section}{منابع}

\begin{latin}
	\begin{itemize}
		\setlength\itemsep{0.6em}
		
		\item[] Art. 29 WP. (2013). Opinion 03/2013 on Purpose Limitation.
		
		\item[] Art. 29 WP. (2014). Opinion 06/2014 on the Notion of Legitimate Interests of the Data Controller under Article 7 of Directive 95/46/EC.
		
		\item[] Art. 29 WP. (2007). Opinion 4/2007 on the concept of personal data.
		
		\item[] Art. 29 WP. (2010). Opinion 1/2010 on the concepts of “controller” and “processor.”
		
		\item[] Art. 29 WP. (2018a). Article 29 Working Party Guidelines on consent under Regulation 2016/679.
		
		\item[] Art. 29 WP. (2018b). Guidelines on transparency under Regulation 2016/679.
		
		\item[] Carey, P. (2018a). Data protection principles. In P. Carey (Ed.), \textit{Data protection: A practical guide to UK and EU law} (5th ed., pp. 32–41). Oxford University Press.
		
		\item[] Coleman, R., \& McCahill, M. (2011). \textit{Surveillance \& crime}. Sage.
		
		\item[] Dehon, E., \& Carey, P. (2018). Fair, lawful, and transparent processing. In P. Carey (Ed.), \textit{Data protection: A practical guide to UK and EU law} (5th ed., pp. 42–65). Oxford University Press.
		
		\item[] European Parliament resolution of 16 February 2017 with recommendations to the Commission on Civil Law Rules on Robotics (2015/2103(INL)).
		
		\item[] Gellman, R. (2019). FAIR INFORMATION PRACTICES: A Basic History.
		
		\item[] Gutwirth, S. (2002). \textit{Privacy and the Information Age}. Rowman \& Littlefield.
		
		\item[] Hoofnagle, C. J., Sloot, B. van der., \& Zuiderveen Borgesius, F. (2019). ‘The European Union General Data Protection Regulation: What It Is and What It Means’. \textit{28 Information and Communications Technology Law} 65.
		
		\item[] Mourby, M., Mackey, E., Elliot, M., Gowans, H., Wallace, S. E., Bell, J., et al. (2018). Are “pseudonymised” data always personal data? Implications of the GDPR for administrative data research in the UK. \textit{Computer Law and Security Review}, 34(2), 222–233.
		
		\item[] Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation), [2016], OJ L 119/1.
		
		\item[] Rodway, S., \& Carey, P. (2018). Outsourcing personal data processing. In P. Carey (Ed.), \textit{Data protection: A practical guide to UK and EU law} (5th ed., pp. 175–183). Oxford University Press.
		
		\item[] Voigt, P., \& von dem Busche, A. (2017). \textit{The EU General Data Protection Regulation (GDPR), a practical guide}. Springer.
		
		\item[] Welfare, D., \& Carey, P. (2018). Territorial scope and terminology. In P. Carey (Ed.), \textit{Data protection: A Practical guide to UK and EU law} (5th ed., pp. 1–31). Oxford University Press.
		
	\end{itemize}
\end{latin}